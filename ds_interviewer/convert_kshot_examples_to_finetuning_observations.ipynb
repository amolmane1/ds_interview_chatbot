{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "590fca2a-ad6c-40e0-a23e-596f769a76f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "## from prompt_templates import kshot_prompt_templates\n",
    "\n",
    "from finetuning.prepare_data import add_observation_to_raw_finetuning_dataset\n",
    "\n",
    "from utils.utils import get_models_metadata, prepare_chat_history, get_default_args\n",
    "\n",
    "from parse import parse\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ae1f8ad6-c740-4e3d-ad6d-bcde3cc39752",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_metadata = get_models_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf11bd8-0392-4d14-89ef-fc68d1153a60",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# ask how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bab19b94-0956-474e-914d-7596a6f53f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "kshot_ask_how_it_works_prompt = kshot_prompt_templates.ask_how_it_works\n",
    "\n",
    "kshot_ask_how_it_works_prompt = kshot_ask_how_it_works_prompt.split(\"Below are some examples:\")[-1]\n",
    "\n",
    "separated_observations = kshot_ask_how_it_works_prompt.split(\"Current section chat:\")[1:]\n",
    "\n",
    "for i in range(len(separated_observations)):\n",
    "    separated_observations[i] = \"Current section chat:\" + separated_observations[i].rstrip()\n",
    "\n",
    "separated_observations[-1] = separated_observations[-1][:-6]\n",
    "\n",
    "separated_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db52c704-19f9-4622-9e31-65b0de79b4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(separated_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd715e6a-197b-457e-b90a-3542ea347a96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "all_observation_details = []\n",
    "for i in range(len(separated_observations)):\n",
    "    print(i)\n",
    "    prompt = separated_observations[i] \\\n",
    "        .rsplit(\"Interviewer: \", maxsplit=1)[0] \\\n",
    "        .replace(\"\\n\\n\\n\", \"\\n{}\\n\\n\".format(get_default_args(prepare_chat_history)['empty_value'])) \\\n",
    "        .replace(\"Details: \\n\", \"Details:\\n\")\n",
    "    completion = \"Interviewer: \" + separated_observations[i].rsplit(\"Interviewer: \", maxsplit=1)[-1]\n",
    "    \n",
    "    prompt_args = parse(models_metadata['ask_how_it_works'][-1]['prompt_template'], \n",
    "                        prompt).named\n",
    "    completion_args = parse(models_metadata['ask_how_it_works'][-1]['completion_template'], \n",
    "                        completion).named\n",
    "    \n",
    "    observation_details = dict(model_name=\"ask_how_it_works\", \n",
    "                           prompt_template=models_metadata['ask_how_it_works'][-1]['prompt_template'], \n",
    "                           completion_template=models_metadata['ask_how_it_works'][-1]['completion_template'], \n",
    "                           prompt_args=prompt_args, \n",
    "                           completion_args=completion_args,\n",
    "                           prompt = prompt,\n",
    "                           completion=completion)\n",
    "    all_observation_details.append(observation_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d6e2c0-ce9f-4322-887a-a41ec0588a38",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2c7c425a-7d4d-47a7-82fe-5e536fa2e46d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = separated_observations[28].rsplit(\"Interviewer: \", maxsplit=1)[0] \\\n",
    "            .replace(\"\\n\\n\\n\", \"\\nNA\\n\\n\") \\\n",
    "            .replace(\"Details: \\n\", \"Details:\\n\")\n",
    "completion = \"Interviewer: \" + separated_observations[28].rsplit(\"Interviewer: \", maxsplit=1)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dc54646d-f8a1-44d3-8b57-f4bb36ee3031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Current section chat:\\nNA\\n\\nDetails:\\nSubject: NA\\nQuestion type: how it works\\nIs question correct: 0\\n'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7697e703-72c1-4cb0-abcb-d386dec963f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Current section chat:\\n{current_section_chat}\\n\\nDetails:\\nSubject: {subject}\\nQuestion type: {question_type}\\nIs question correct: {is_completion_correct}\\n'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_metadata['ask_how_it_works'][-1]['prompt_template']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2c6b4a77-e649-4726-a2e6-291e6cb7bc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_args = parse(models_metadata['ask_how_it_works'][-1]['prompt_template'], \n",
    "                    prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a82a3352-ac37-46f3-8b57-4cd53e165cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'current_section_chat': 'NA',\n",
       " 'subject': 'NA',\n",
       " 'question_type': 'how it works',\n",
       " 'is_completion_correct': '0'}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_args.named"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b4f7b04b-fcd9-4c57-b8ce-1ec4289d0430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Interviewer: What are the advantages and disadvantages of using precision as a metric?'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "00f62f17-fb36-40f6-adcc-e3be004b132e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result () {'b': '\\n', 'd': 'd'}>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse(\"a{b}c{d}\", \"a\\ncd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5094cd-1a91-437c-b72d-e928a8aa312e",
   "metadata": {},
   "source": [
    "### upload to ft dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce1e08f3-d293-4a94-b18b-ca468d912414",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_observation_details)):\n",
    "    print(i)\n",
    "    add_observation_to_raw_finetuning_dataset(all_observation_details[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10173341-8aaf-4049-9328-a1abc4ab6651",
   "metadata": {},
   "source": [
    "# validate answer how it works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053bc023-eb18-4e80-ade3-b95afe967234",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## first set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10f137db-757d-4151-b7dc-e2a75d75ac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kshot_validate_answer_how_it_works_prompt = kshot_prompt_templates.validate_answer_how_it_works\n",
    "\n",
    "kshot_validate_answer_how_it_works_prompt = kshot_validate_answer_how_it_works_prompt.split(\"Below are some correct examples:\")[-1].lstrip()\n",
    "\n",
    "\n",
    "\n",
    "separated_observations = kshot_validate_answer_how_it_works_prompt.split(\"Current section chat:\")\n",
    "\n",
    "\n",
    "separated_observations = separated_observations[1:]\n",
    "\n",
    "for i in range(len(separated_observations)):\n",
    "    separated_observations[i] = \"Current section chat:\" + separated_observations[i].rstrip()\n",
    "\n",
    "separated_observations[-1] = separated_observations[-1][:-6]\n",
    "\n",
    "separated_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "19a16bcb-7bd0-4b5a-801c-3faf7076707c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(separated_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5d667e8-9f98-4b81-8cd3-12d1347eb422",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "all_observation_details = []\n",
    "for i in range(len(separated_observations)):\n",
    "    print(i)\n",
    "    prompt = separated_observations[i] \\\n",
    "        .rsplit(\"Correct Response: \", maxsplit=1)[0] \\\n",
    "        .replace(\"\\n\\n\\n\", \"\\n{}\\n\\n\".format(get_default_args(prepare_chat_history)['empty_value'])) \\\n",
    "        .replace(\"Details: \\n\", \"Details:\\n\")\n",
    "    completion = \"Correct Response: \" + separated_observations[i].rsplit(\"Correct Response: \", maxsplit=1)[-1]\n",
    "    \n",
    "    prompt_args = parse(models_metadata['validate_answer_how_it_works'][-1]['prompt_template'], \n",
    "                        prompt).named\n",
    "    completion_args = parse(models_metadata['validate_answer_how_it_works'][-1]['completion_template'], \n",
    "                        completion).named\n",
    "    \n",
    "    observation_details = dict(model_name=\"validate_answer_how_it_works\", \n",
    "                           prompt_template=models_metadata['validate_answer_how_it_works'][-1]['prompt_template'], \n",
    "                           completion_template=models_metadata['validate_answer_how_it_works'][-1]['completion_template'], \n",
    "                           prompt_args=prompt_args, \n",
    "                           completion_args=completion_args,\n",
    "                           prompt = prompt,\n",
    "                           completion=completion)\n",
    "    all_observation_details.append(observation_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b50b1d7a-35ae-4199-b71c-47ef539eab86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'validate_answer_how_it_works',\n",
       " 'prompt_template': 'Current section chat:\\n{current_section_chat}\\n\\nDetails:\\nQuestion type: {question_type}\\nIs validation correct: {is_completion_correct}',\n",
       " 'completion_template': 'Correct Response: {correct_response}\\nValidation of response: {validation_of_response}',\n",
       " 'prompt_args': {'current_section_chat': \"Interviewer: How does undersampling the majority class help with class imbalance?\\nApplicant: I don't understand\",\n",
       "  'question_type': 'how it works',\n",
       "  'is_completion_correct': '1\\n'},\n",
       " 'completion_args': {'correct_response': 'By undersampling the majority class, the ratio between the number of observations in the majority and minority classes decreases, making the dataset less imbalanced.',\n",
       "  'validation_of_response': '0'},\n",
       " 'prompt': \"Current section chat:\\nInterviewer: How does undersampling the majority class help with class imbalance?\\nApplicant: I don't understand\\n\\nDetails:\\nQuestion type: how it works\\nIs validation correct: 1\\n\",\n",
       " 'completion': 'Correct Response: By undersampling the majority class, the ratio between the number of observations in the majority and minority classes decreases, making the dataset less imbalanced.\\nValidation of response: 0'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_observation_details[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2266aebc-389f-49bd-bed5-0d888052cda1",
   "metadata": {},
   "source": [
    "## set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "711fabc0-be98-43fa-8188-4dff93d14d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "kshot_validate_answer_how_it_works_prompt = kshot_prompt_templates.validate_answer_how_it_works_2\n",
    "separated_observations = kshot_validate_answer_how_it_works_prompt.split(\"Current section chat:\")\n",
    "separated_observations = separated_observations[1:]\n",
    "\n",
    "for i in range(len(separated_observations)):\n",
    "    separated_observations[i] = \"Current section chat:\" + separated_observations[i].rstrip()\n",
    "\n",
    "# separated_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cec4e286-3ce0-4bf2-8235-05eaa6ca0569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(separated_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "02d9d3ca-7653-49ec-8e3c-3a27fa3e8049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "all_observation_details = []\n",
    "for i in range(len(separated_observations)):\n",
    "    print(i)\n",
    "    prompt = separated_observations[i] \\\n",
    "        .rsplit(\"Correct Response: \", maxsplit=1)[0] \\\n",
    "        .replace(\"\\n\\n\\n\", \"\\n{}\\n\\n\".format(get_default_args(prepare_chat_history)['empty_value'])) \\\n",
    "        .replace(\"Details: \\n\", \"Details:\\n\")\n",
    "    completion = \"Correct Response: \" + separated_observations[i].rsplit(\"Correct Response: \", maxsplit=1)[-1]\n",
    "    \n",
    "    prompt_args = parse(models_metadata['validate_answer_how_it_works'][-1]['prompt_template'], \n",
    "                        prompt).named\n",
    "    completion_args = parse(models_metadata['validate_answer_how_it_works'][-1]['completion_template'], \n",
    "                        completion).named\n",
    "    \n",
    "    observation_details = dict(model_name=\"validate_answer_how_it_works\", \n",
    "                           prompt_template=models_metadata['validate_answer_how_it_works'][-1]['prompt_template'], \n",
    "                           completion_template=models_metadata['validate_answer_how_it_works'][-1]['completion_template'], \n",
    "                           prompt_args=prompt_args, \n",
    "                           completion_args=completion_args,\n",
    "                           prompt = prompt,\n",
    "                           completion=completion)\n",
    "    all_observation_details.append(observation_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3f98b813-906f-41e3-91c6-7e5464b5ebe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'validate_answer_how_it_works',\n",
       " 'prompt_template': 'Current section chat:\\n{current_section_chat}\\n\\nDetails:\\nQuestion type: {question_type}\\nIs validation correct: {is_completion_correct}\\n',\n",
       " 'completion_template': 'Correct Response: {correct_response}\\nValidation of response: {validation_of_response}',\n",
       " 'prompt_args': {'current_section_chat': \"Interviewer: How does one-hot encoding work?\\nApplicant: Sorry, i don't know.\",\n",
       "  'question_type': 'how it works',\n",
       "  'is_completion_correct': '1'},\n",
       " 'completion_args': {'correct_response': 'One-hot encoding converts each unique categorical value to a binary vector.',\n",
       "  'validation_of_response': '0'},\n",
       " 'prompt': \"Current section chat:\\nInterviewer: How does one-hot encoding work?\\nApplicant: Sorry, i don't know.\\n\\nDetails:\\nQuestion type: how it works\\nIs validation correct: 1\\n\",\n",
       " 'completion': 'Correct Response: One-hot encoding converts each unique categorical value to a binary vector.\\nValidation of response: 0'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_observation_details[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67a97cf-2c8a-409d-a0f5-a7ddc55aab5e",
   "metadata": {},
   "source": [
    "### upload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "80b0710d-2b00-4b95-960a-d5001e736918",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_observation_details)):\n",
    "    print(i)\n",
    "    add_observation_to_raw_finetuning_dataset(all_observation_details[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
