{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a553a3e-5f86-4848-8074-6f304dd73cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import openai\n",
    "import pandas as pd\n",
    "import logging\n",
    "from IPython.display import clear_output\n",
    "from copy import deepcopy\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from parse import parse\n",
    "\n",
    "from finetuning import prepare_data\n",
    "from utils import graph\n",
    "from utils import utils\n",
    "from nodes.node_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af4a70ca-1852-4bf4-8df9-686ff3213576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 7.0.4 (20221203.1631)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"252pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 252.38 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-184 248.38,-184 248.38,4 -4,4\"/>\n",
       "<!-- ask_what_you_did -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>ask_what_you_did</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"122.19\" cy=\"-162\" rx=\"77.5\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"122.19\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">ask_what_you_did</text>\n",
       "</g>\n",
       "<!-- ask_how_it_works -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>ask_how_it_works</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"122.19\" cy=\"-90\" rx=\"77.5\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"122.19\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">ask_how_it_works</text>\n",
       "</g>\n",
       "<!-- ask_what_you_did&#45;&gt;ask_how_it_works -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>ask_what_you_did&#45;&gt;ask_how_it_works</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M122.19,-143.7C122.19,-136.41 122.19,-127.73 122.19,-119.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"125.69,-119.61 122.19,-109.61 118.69,-119.61 125.69,-119.61\"/>\n",
       "</g>\n",
       "<!-- validate_answer_how_it_works -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>validate_answer_how_it_works</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"122.19\" cy=\"-18\" rx=\"122.38\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"122.19\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">validate_answer_how_it_works</text>\n",
       "</g>\n",
       "<!-- ask_how_it_works&#45;&gt;validate_answer_how_it_works -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>ask_how_it_works&#45;&gt;validate_answer_how_it_works</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M122.19,-71.7C122.19,-64.41 122.19,-55.73 122.19,-47.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"125.69,-47.62 122.19,-37.62 118.69,-47.62 125.69,-47.62\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<AGraph <Swig Object of type 'Agraph_t *' at 0x12ce5ed90>>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interview_graph = graph.create_interview_flowchart2()\n",
    "\n",
    "graph.plot_graph(interview_graph)\n",
    "graph.plot_graph(interview_graph.nodes[\"algorithm selection\"]['graph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d97edb18-79b8-421e-a074-b658812fc95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_what_applicant_has_done_in_ipynb():\n",
    "    applicant_approaches = {\n",
    "        'algorithm selection': 'elastic net',\n",
    "        'categorical encoding': 'one hot encoding'\n",
    "    }\n",
    "    applicant_approaches_json = json.dumps(applicant_approaches)\n",
    "    return applicant_approaches_json\n",
    "\n",
    "what_applicant_has_done_in_ipynb = identify_what_applicant_has_done_in_ipynb()\n",
    "what_applicant_has_done_in_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65b15f5e-b33e-4454-b18f-8c43bb0a4ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"algorithm selection\": \"elastic net\", \"categorical encoding\": \"one hot encoding\"}'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what_applicant_has_done_in_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03588f09-6f46-4ce3-a497-a864100e0107",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Context:\n",
    "{context}\n",
    "###\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "681736c0-9334-448c-9931-78ef0a443b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Context:\\n{\"algorithm selection\": \"elastic net\", \"categorical encoding\": \"one hot encoding\"}\\n###\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template.format(context=what_applicant_has_done_in_ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1810f415-9d83-47b9-8a56-10e64a61199f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confirm_what_applicant_did(current_section_name, context, carryover_data, validate_async=True, chat_history_by_section=[[]], **kwargs):\n",
    "    model_metadata, model_version = get_model_metadata('ask_what_you_did', kwargs[\"model_version\"] if \"model_version\" in kwargs.keys() else None)\n",
    "    prompt_args = dict(\n",
    "        current_section_chat=prepare_chat_history(chat_history_by_section[-1]),\n",
    "                      subject=current_section_name,\n",
    "                      is_completion_correct=1)\n",
    "    observation_prompt = model_metadata['prompt_template'].format(**prompt_args)\n",
    "    \n",
    "    kshot_prompt = prepare_kshot_prompt_using_levenshtein_distance(model_name='ask_what_you_did', \n",
    "                                                                   model_metadata=model_metadata, \n",
    "                                                                   prompt_args=prompt_args, \n",
    "                                                                   observation_prompt=observation_prompt)\n",
    "    completion = create_openai_completion(kshot_prompt, args=default_arguments_for_openai_generation)\n",
    "    print(\"completion: \" + completion)\n",
    "    completion_args = parse(model_metadata['completion_template'], \n",
    "                            completion).named\n",
    "    observation_details = dict(model_name=\"ask_what_you_did\", \n",
    "                               model_version=model_version,\n",
    "                               prompt_template=model_metadata['prompt_template'], \n",
    "                               completion_template=model_metadata['completion_template'], \n",
    "                               prompt_args=prompt_args, \n",
    "                               completion_args=completion_args,\n",
    "                               prompt = observation_prompt,\n",
    "                               completion=completion)\n",
    "    completion_args_to_use_for_interview = submit_observation_for_finetuning_validation(observation_details, \n",
    "                                                                                        validate_async=validate_async)\n",
    "\n",
    "    new_chat_lines = []\n",
    "    new_chat_lines.append(\"Interviewer: \" + completion_args_to_use_for_interview['interviewer_dialogue'])\n",
    "    new_chat_lines.append(get_user_input())\n",
    "    return dict(routing_value=None, \n",
    "                new_chat_lines=new_chat_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1de165a6-1bd4-4490-b1f9-b30cb5f24db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interview_graph.nodes[\"algorithm selection\"]['graph'].nodes['ask_how_it_works']['function_args']['subject'] = \"DBSCAN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2665bfd9-ce4d-440c-a59c-b60c2388c923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_node = interview_graph.nodes[\"dealing with categorical values\"]['graph'].nodes[\"ask_how_it_works\"]\n",
    "\n",
    "# # section_graph = interview_graph.nodes[\"dealing with categorical values\"]['graph']\n",
    "# # [n for n,d in section_graph.in_degree() if d==0] \n",
    "\n",
    "# current_node_function_args = deepcopy(current_node['function_args'])\n",
    "# current_node_function_args['carryover_data'] = dict(algorithm_selection=dict(subject='Ordinal encoding'))\n",
    "# current_node_function_args['chat_history_by_section'] = [[]]\n",
    "\n",
    "# current_node_output = current_node['function'](**current_node_function_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d437360-77f9-40cb-8592-a954654c354c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat\n",
    "\n",
    "# each list within this variable is the conversation in a particular section. each string within that list is the ordered dialogue from each member of the interview\n",
    "chat_history_by_section = []\n",
    "flattened_chat_history = \"\"\n",
    "\n",
    "# list of the nodes that have been visited till the current point\n",
    "sections_visited_names = []\n",
    "nodes_visited_names = []\n",
    "\n",
    "validate_async = False\n",
    "\n",
    "is_interview_complete = False\n",
    "\n",
    "carryover_data = {\n",
    "\"dealing with categorical values\": {\n",
    "    \"ask_how_it_works\": {\n",
    "        \"subject\": \"hash encoding\"\n",
    "    }\n",
    "},\n",
    "\"algorithm selection\": {\n",
    "    \"ask_what_you_did\": {\n",
    "        \"subject\": \"\"\n",
    "    }\n",
    "}\n",
    "}\n",
    "\n",
    "def get_first_node_in_graph(graph):\n",
    "    first_node_name = [node_name for node_name, in_degrees in graph.in_degree() if in_degrees==0][0]\n",
    "    first_node = graph.nodes[first_node_name]\n",
    "    return first_node_name, first_node\n",
    "\n",
    "def get_next_node(graph, current_node_name, current_node_output):\n",
    "    outgoing_edges = list(graph.out_edges(current_node_name, data=True))\n",
    "    if len(outgoing_edges) == 0:\n",
    "        return None, None\n",
    "    else:\n",
    "        if len(outgoing_edges) == 1:\n",
    "            edge_to_traverse = outgoing_edges[0]\n",
    "        else:\n",
    "            for edge in outgoing_edges:\n",
    "                if current_node_output['routing_value'] in edge[-1]['passthrough_values']:\n",
    "                    edge_to_traverse = edge\n",
    "        next_node_name = edge_to_traverse[1]\n",
    "        next_node = graph.nodes[next_node_name]\n",
    "        return next_node_name, next_node\n",
    "    \n",
    "current_section_name, current_section = get_first_node_in_graph(interview_graph)\n",
    "current_section_graph = current_section['graph']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0df3d3ba-d391-43d0-8e7a-9e9cef72e600",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interviewer: Thank you for taking the time out to interview with us. \n",
      "    In this interview, we will cover a range of topics and ask questions to assess your skill level as a Data Scientist. \n",
      "    If you don't understand a question, feel free to ask questions to get clarification.\n",
      "    Let's get started.\n",
      "Interviewer: What algorithm did you use?\n",
      "Applicant: I used an ensemble of random forest, SVM, and liner regression. The results from these models were averaged to get the final prediction.\n",
      "Interviewer: Can you explain to me how an SVM works?\n",
      "Applicant: an SVM draws a line between the positive and negative classes, finds the middle point, and uses that to construct a decision boundary.\n",
      "Interviewer: How did you encode the categorical values in the dataset?\n",
      "Applicant: I used hash encoding\n",
      "Interviewer: How does hash encoding work?\n",
      "Applicant: the string values of the categorical column are hashed. The resulting hashed vector is used in the dataset.\n",
      "Interviewer: Okay, those were all the topics we wanted to cover. Thank you again for taking the time out to interview with us.\n",
      "    We will get back to you with our decision. Have a nice day!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# traverse through sections\n",
    "while not is_interview_complete:\n",
    "    chat_history_by_section.append([])\n",
    "    current_node_name, current_node = get_first_node_in_graph(current_section_graph)\n",
    "    # print(\"\\n\\ncurrent section: \" + current_section_name)\n",
    "    # print(\"current node: \" + current_node_name)\n",
    "    is_section_complete = False\n",
    "    # traverse within section\n",
    "    while not is_section_complete:\n",
    "        # access current node from current section\n",
    "        # prep args for current node function\n",
    "        current_node_function_args = deepcopy(current_node['function_args']) if 'function_args' in current_node else {}\n",
    "        current_node_function_args['current_section_name'] = current_section_name\n",
    "        # current_node_function_args['current_node_name'] = current_node_name\n",
    "        current_node_function_args['carryover_data'] = carryover_data\n",
    "        current_node_function_args['validate_async'] = validate_async\n",
    "        current_node_function_args['chat_history_by_section'] = chat_history_by_section\n",
    "\n",
    "        # call function\n",
    "        current_node_output = current_node['function'](**current_node_function_args)\n",
    "        \n",
    "        if current_node_output['new_chat_lines']:\n",
    "            # store return values in appropriate variables (chat_history)\n",
    "            chat_history_by_section[-1].extend(current_node_output['new_chat_lines'])\n",
    "            flattened_chat_history += \"\\n\" + \"\\n\".join(current_node_output['new_chat_lines'])\n",
    "            clear_output()\n",
    "            print(flattened_chat_history)\n",
    "    \n",
    "        # update nodes_visited\n",
    "        nodes_visited_names.append(current_node_name)\n",
    "    \n",
    "        # figure out next node to visit\n",
    "        current_node_name, current_node = get_next_node(current_section_graph, current_node_name, current_node_output)\n",
    "        if current_node_name is None:\n",
    "            # prepare routing_value (result of a section)\n",
    "            current_section_output = dict(routing_value=1, \n",
    "                                          new_chat_line=None) \n",
    "            is_section_complete = True\n",
    "\n",
    "    \n",
    "    sections_visited_names.append(current_section_name)\n",
    "    # get new section\n",
    "    current_section_name, current_section = get_next_node(interview_graph, current_section_name, current_section_output)\n",
    "    if current_section_name is None:\n",
    "        is_interview_complete = True\n",
    "        break\n",
    "    current_section_graph = current_section['graph']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
