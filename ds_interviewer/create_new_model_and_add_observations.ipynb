{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ca76c9f-4da6-4d06-a90b-0d1d9f153bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.models_metadata import get_model_metadata, add_new_model_version\n",
    "from finetuning import prepare_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f532bb2-caa5-4b3c-963b-39b22b0ae9d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# ask_what_you_did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a692111f-0299-4e1f-928d-f12054f0d997",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_version_metadata = {\n",
    "    'prompt_template': \\\n",
    "\"\"\"Details:\n",
    "Current section chat:\n",
    "{current_section_chat}\n",
    "\n",
    "Subject: {subject}\n",
    "Is question correct: {is_completion_correct}\n",
    "###\n",
    "\"\"\",\n",
    "    'completion_template': \\\n",
    "\"\"\"Interviewer: {interviewer_dialogue}\"\"\",\n",
    "    'kshot_header': \\\n",
    "\"\"\"Interviewer is interviewing Applicant for a job as a Data Scientist.\n",
    "Interviewer asks Applicant a question in the following format:\n",
    "\n",
    "Current section chat:\n",
    "$<Conversation so far between Interviewer and Applicant. This may be empty.>\n",
    "\n",
    "Details:\n",
    "Subject: $<the subject Interviewer is to ask a question about>\n",
    "Is question correct: $<1 or 0 - whether the question Interviewer asks is of the right type or not>\n",
    "###\n",
    "Interviewer: $<Interviewer's question about the subject>\n",
    "\n",
    "Below are some correct examples:\n",
    "\n",
    "\"\"\",\n",
    "    'finetuned_model_name': None\n",
    "}\n",
    "\n",
    "add_new_model_version(\"ask_what_you_did\", new_model_version_metadata, set_as_best_model_version=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e108e757-17b0-40ec-b80f-46514ebf2612",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metadata, model_version = get_model_metadata(\"ask_what_you_did\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59ba0579-3f5c-458d-806c-2264d543ab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_args = dict(\n",
    "    current_section_chat=\"NA\",\n",
    "    subject=\"Dealing with class imbalance\",\n",
    "                  is_completion_correct=1)\n",
    "completion_args = dict(interviewer_dialogue=\"How did you deal with class imbalance in the dataset?\")\n",
    "observation_prompt = model_metadata['prompt_template'].format(**prompt_args)\n",
    "completion = model_metadata['completion_template'].format(**completion_args)\n",
    "observation_details = dict(model_name=\"ask_what_you_did\", \n",
    "                               model_version=\"09.01.23-1\",\n",
    "                               prompt_template=model_metadata['prompt_template'], \n",
    "                               completion_template=model_metadata['completion_template'], \n",
    "                               prompt_args=prompt_args, \n",
    "                               completion_args=completion_args,\n",
    "                               prompt = observation_prompt,\n",
    "                               completion=completion)\n",
    "\n",
    "prepare_data.add_observation_to_finetuning_datasets(observation_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2a63a8-1f2b-4266-b08e-e3e221607eff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# confirm_what_applicant_did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "157d7fe4-010e-4ec0-b016-d3f74bb614a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_version_metadata = {\n",
    "    'model_version': None,\n",
    "    'prompt_template': \\\n",
    "\"\"\"Context:\n",
    "{context}\n",
    "\n",
    "Current section chat:\n",
    "{current_section_chat}\n",
    "\n",
    "Details:\n",
    "Section: {section}\n",
    "Is question correct: {is_completion_correct}\n",
    "###\n",
    "\"\"\",\n",
    "    'completion_template': \\\n",
    "\"\"\"Interviewer: {interviewer_dialogue}\"\"\",\n",
    "    'kshot_header': \\\n",
    "\"\"\"Interviewer is interviewing Applicant for a job as a Data Scientist.\n",
    "Interviewer asks Applicant a question in the following format:\n",
    "\n",
    "Context:\n",
    "$<a summary of the techniques the applicant has used for each section of the interview>\n",
    "\n",
    "Current section chat:\n",
    "$<Conversation so far between Interviewer and Applicant. This may be empty.>\n",
    "\n",
    "Details:\n",
    "Section: $<the section Interviewer is to ask a question about>\n",
    "Is question correct: $<1 or 0 - whether the question Interviewer asks is of the right type or not>\n",
    "###\n",
    "Interviewer: $<Interviewer's question about the subject>\n",
    "\n",
    "Below are some correct examples:\n",
    "\n",
    "\"\"\",\n",
    "    'finetuned_model_name': None\n",
    "}\n",
    "\n",
    "add_new_model_version(\"confirm_what_applicant_did\", new_model_version_metadata, set_as_best_model_version=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c8c0f79-1f47-4a2d-9325-11a4e75b9fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metadata, model_version = get_model_metadata(\"confirm_what_applicant_did\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "425dc24a-a7a3-446b-853a-be7175417e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_args = dict(\n",
    "    context=\"\"\"{\"algorithm selection\": \"SVM\"}\"\"\",\n",
    "    current_section_chat=\"NA\",\n",
    "    section=\"algorithm selection\",\n",
    "                  is_completion_correct=1)\n",
    "completion_args = dict(interviewer_dialogue=\"From your submission, I saw that you used SVM to learn the data. Could you confirm this?\")\n",
    "observation_prompt = model_metadata['prompt_template'].format(**prompt_args)\n",
    "completion = model_metadata['completion_template'].format(**completion_args)\n",
    "observation_details = dict(model_name=\"confirm_what_applicant_did\", \n",
    "                               model_version=model_version,\n",
    "                               prompt_template=model_metadata['prompt_template'], \n",
    "                               completion_template=model_metadata['completion_template'], \n",
    "                               prompt_args=prompt_args, \n",
    "                               completion_args=completion_args,\n",
    "                               prompt = observation_prompt,\n",
    "                               completion=completion)\n",
    "\n",
    "prepare_data.add_observation_to_finetuning_datasets(observation_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252adbaa-0ee2-4e26-bc1a-1d79f27c1f2d",
   "metadata": {},
   "source": [
    "# route_answer_to_confirm_what_applicant_did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "408d6487-019c-4d9c-a06b-49e5629f062f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_version_metadata = {\n",
    "    'model_version': None,\n",
    "    'prompt_template': \\\n",
    "\"\"\"Current section chat:\n",
    "{current_section_chat}\n",
    "\n",
    "Details:\n",
    "Is routing correct: {is_completion_correct}\n",
    "###\n",
    "\"\"\",\n",
    "    'completion_template': \\\n",
    "\"\"\"Route: {route}\"\"\",\n",
    "    'kshot_header': \\\n",
    "\"\"\"Interviewer is interviewing Applicant for a job as a Data Scientist.\n",
    "Interviewer assigns Applicant's answer to integer categories in the following format:\n",
    "\n",
    "Current section chat:\n",
    "$<Conversation so far between Interviewer and Applicant. This may be empty.>\n",
    "\n",
    "Details:\n",
    "Is routing correct: $<1 or 0 - whether the category Interviewer assigns to Applicant's answer is of the right type or not>\n",
    "###\n",
    "Route: $<whether applicant confirms that they used a certain approach (1) or not (0)>\n",
    "\n",
    "Below are some correct examples:\n",
    "\n",
    "\"\"\",\n",
    "    'finetuned_model_name': None\n",
    "}\n",
    "\n",
    "add_new_model_version(\"route_answer_to_confirm_what_applicant_did\", new_model_version_metadata, set_as_best_model_version=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a2344f6-ea73-4403-a6c0-78d15793abad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metadata, model_version = get_model_metadata(\"route_answer_to_confirm_what_applicant_did\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62296b61-0a9f-433b-bb01-95522033a04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_args = dict(\n",
    "    current_section_chat=\"Interviewer: Could you confirm whether you used SVM for training on the data?\\nApplicant: Yeah, I did.\",\n",
    "    is_completion_correct=1)\n",
    "completion_args = dict(route=\"1\")\n",
    "observation_prompt = model_metadata['prompt_template'].format(**prompt_args)\n",
    "completion = model_metadata['completion_template'].format(**completion_args)\n",
    "observation_details = dict(model_name=\"route_answer_to_confirm_what_applicant_did\", \n",
    "                               model_version=model_version,\n",
    "                               prompt_template=model_metadata['prompt_template'], \n",
    "                               completion_template=model_metadata['completion_template'], \n",
    "                               prompt_args=prompt_args, \n",
    "                               completion_args=completion_args,\n",
    "                               prompt = observation_prompt,\n",
    "                               completion=completion)\n",
    "\n",
    "prepare_data.add_observation_to_finetuning_datasets(observation_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "045d2926-2e3d-4ed6-b833-838d75cacf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_args = dict(\n",
    "    current_section_chat=\"Interviewer: Could you confirm whether you used one hot encoding to encode the vategorical variables?\\nApplicant: No, I didn't use that.\",\n",
    "    is_completion_correct=1)\n",
    "completion_args = dict(route=\"0\")\n",
    "observation_prompt = model_metadata['prompt_template'].format(**prompt_args)\n",
    "completion = model_metadata['completion_template'].format(**completion_args)\n",
    "observation_details = dict(model_name=\"route_answer_to_confirm_what_applicant_did\", \n",
    "                               model_version=model_version,\n",
    "                               prompt_template=model_metadata['prompt_template'], \n",
    "                               completion_template=model_metadata['completion_template'], \n",
    "                               prompt_args=prompt_args, \n",
    "                               completion_args=completion_args,\n",
    "                               prompt = observation_prompt,\n",
    "                               completion=completion)\n",
    "\n",
    "prepare_data.add_observation_to_finetuning_datasets(observation_details)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
