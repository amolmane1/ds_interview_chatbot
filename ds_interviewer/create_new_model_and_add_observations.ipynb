{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ca76c9f-4da6-4d06-a90b-0d1d9f153bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.models_metadata import get_model_metadata, add_new_model_version\n",
    "from finetuning import prepare_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f532bb2-caa5-4b3c-963b-39b22b0ae9d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# ask_what_you_did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a692111f-0299-4e1f-928d-f12054f0d997",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_version_metadata = {\n",
    "    'prompt_template': \\\n",
    "\"\"\"Details:\n",
    "Current section chat:\n",
    "{current_section_chat}\n",
    "\n",
    "Subject: {subject}\n",
    "Is question correct: {is_completion_correct}\n",
    "###\n",
    "\"\"\",\n",
    "    'completion_template': \\\n",
    "\"\"\"Interviewer: {interviewer_dialogue}\"\"\",\n",
    "    'kshot_header': \\\n",
    "\"\"\"Interviewer is interviewing Applicant for a job as a Data Scientist.\n",
    "Interviewer asks Applicant a question in the following format:\n",
    "\n",
    "Current section chat:\n",
    "$<Conversation so far between Interviewer and Applicant. This may be empty.>\n",
    "\n",
    "Details:\n",
    "Subject: $<the subject Interviewer is to ask a question about>\n",
    "Is question correct: $<1 or 0 - whether the question Interviewer asks is of the right type or not>\n",
    "###\n",
    "Interviewer: $<Interviewer's question about the subject>\n",
    "\n",
    "Below are some correct examples:\n",
    "\n",
    "\"\"\",\n",
    "    'finetuned_model_name': None\n",
    "}\n",
    "\n",
    "add_new_model_version(\"ask_what_you_did\", new_model_version_metadata, set_as_best_model_version=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e108e757-17b0-40ec-b80f-46514ebf2612",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metadata, model_version = get_model_metadata(\"ask_what_you_did\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59ba0579-3f5c-458d-806c-2264d543ab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_args = dict(\n",
    "    current_section_chat=\"NA\",\n",
    "    subject=\"Dealing with class imbalance\",\n",
    "                  is_completion_correct=1)\n",
    "completion_args = dict(interviewer_dialogue=\"How did you deal with class imbalance in the dataset?\")\n",
    "observation_prompt = model_metadata['prompt_template'].format(**prompt_args)\n",
    "completion = model_metadata['completion_template'].format(**completion_args)\n",
    "observation_details = dict(model_name=\"ask_what_you_did\", \n",
    "                               model_version=\"09.01.23-1\",\n",
    "                               prompt_template=model_metadata['prompt_template'], \n",
    "                               completion_template=model_metadata['completion_template'], \n",
    "                               prompt_args=prompt_args, \n",
    "                               completion_args=completion_args,\n",
    "                               prompt = observation_prompt,\n",
    "                               completion=completion)\n",
    "\n",
    "prepare_data.add_observation_to_finetuning_datasets(observation_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2a63a8-1f2b-4266-b08e-e3e221607eff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# confirm_what_applicant_did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "157d7fe4-010e-4ec0-b016-d3f74bb614a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_version_metadata = {\n",
    "    'model_version': None,\n",
    "    'prompt_template': \\\n",
    "\"\"\"Context:\n",
    "{context}\n",
    "\n",
    "Current section chat:\n",
    "{current_section_chat}\n",
    "\n",
    "Details:\n",
    "Section: {section}\n",
    "Is question correct: {is_completion_correct}\n",
    "###\n",
    "\"\"\",\n",
    "    'completion_template': \\\n",
    "\"\"\"Interviewer: {interviewer_dialogue}\"\"\",\n",
    "    'kshot_header': \\\n",
    "\"\"\"Interviewer is interviewing Applicant for a job as a Data Scientist.\n",
    "Interviewer asks Applicant a question in the following format:\n",
    "\n",
    "Context:\n",
    "$<a summary of the techniques the applicant has used for each section of the interview>\n",
    "\n",
    "Current section chat:\n",
    "$<Conversation so far between Interviewer and Applicant. This may be empty.>\n",
    "\n",
    "Details:\n",
    "Section: $<the section Interviewer is to ask a question about>\n",
    "Is question correct: $<1 or 0 - whether the question Interviewer asks is of the right type or not>\n",
    "###\n",
    "Interviewer: $<Interviewer's question about the subject>\n",
    "\n",
    "Below are some correct examples:\n",
    "\n",
    "\"\"\",\n",
    "    'finetuned_model_name': None\n",
    "}\n",
    "\n",
    "add_new_model_version(\"confirm_what_applicant_did\", new_model_version_metadata, set_as_best_model_version=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c8c0f79-1f47-4a2d-9325-11a4e75b9fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metadata, model_version = get_model_metadata(\"confirm_what_applicant_did\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "425dc24a-a7a3-446b-853a-be7175417e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_args = dict(\n",
    "    context=\"\"\"{\"algorithm selection\": \"SVM\"}\"\"\",\n",
    "    current_section_chat=\"NA\",\n",
    "    section=\"algorithm selection\",\n",
    "                  is_completion_correct=1)\n",
    "completion_args = dict(interviewer_dialogue=\"From your submission, I saw that you used SVM to learn the data. Could you confirm this?\")\n",
    "observation_prompt = model_metadata['prompt_template'].format(**prompt_args)\n",
    "completion = model_metadata['completion_template'].format(**completion_args)\n",
    "observation_details = dict(model_name=\"confirm_what_applicant_did\", \n",
    "                               model_version=model_version,\n",
    "                               prompt_template=model_metadata['prompt_template'], \n",
    "                               completion_template=model_metadata['completion_template'], \n",
    "                               prompt_args=prompt_args, \n",
    "                               completion_args=completion_args,\n",
    "                               prompt = observation_prompt,\n",
    "                               completion=completion)\n",
    "\n",
    "prepare_data.add_observation_to_finetuning_datasets(observation_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252adbaa-0ee2-4e26-bc1a-1d79f27c1f2d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# route_answer_to_confirm_what_applicant_did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "408d6487-019c-4d9c-a06b-49e5629f062f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_version_metadata = {\n",
    "    'model_version': None,\n",
    "    'prompt_template': \\\n",
    "\"\"\"Current section chat:\n",
    "{current_section_chat}\n",
    "\n",
    "Details:\n",
    "Is routing correct: {is_completion_correct}\n",
    "###\n",
    "\"\"\",\n",
    "    'completion_template': \\\n",
    "\"\"\"Route: {route}\"\"\",\n",
    "    'kshot_header': \\\n",
    "\"\"\"Interviewer is interviewing Applicant for a job as a Data Scientist.\n",
    "Interviewer assigns Applicant's answer to integer categories in the following format:\n",
    "\n",
    "Current section chat:\n",
    "$<Conversation so far between Interviewer and Applicant. This may be empty.>\n",
    "\n",
    "Details:\n",
    "Is routing correct: $<1 or 0 - whether the category Interviewer assigns to Applicant's answer is of the right type or not>\n",
    "###\n",
    "Route: $<whether applicant confirms that they used a certain approach (1) or not (0)>\n",
    "\n",
    "Below are some correct examples:\n",
    "\n",
    "\"\"\",\n",
    "    'finetuned_model_name': None\n",
    "}\n",
    "\n",
    "add_new_model_version(\"route_answer_to_confirm_what_applicant_did\", new_model_version_metadata, set_as_best_model_version=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a2344f6-ea73-4403-a6c0-78d15793abad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metadata, model_version = get_model_metadata(\"route_answer_to_confirm_what_applicant_did\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62296b61-0a9f-433b-bb01-95522033a04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_args = dict(\n",
    "    current_section_chat=\"Interviewer: Could you confirm whether you used SVM for training on the data?\\nApplicant: Yeah, I did.\",\n",
    "    is_completion_correct=1)\n",
    "completion_args = dict(route=\"1\")\n",
    "observation_prompt = model_metadata['prompt_template'].format(**prompt_args)\n",
    "completion = model_metadata['completion_template'].format(**completion_args)\n",
    "observation_details = dict(model_name=\"route_answer_to_confirm_what_applicant_did\", \n",
    "                               model_version=model_version,\n",
    "                               prompt_template=model_metadata['prompt_template'], \n",
    "                               completion_template=model_metadata['completion_template'], \n",
    "                               prompt_args=prompt_args, \n",
    "                               completion_args=completion_args,\n",
    "                               prompt = observation_prompt,\n",
    "                               completion=completion)\n",
    "\n",
    "prepare_data.add_observation_to_finetuning_datasets(observation_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "045d2926-2e3d-4ed6-b833-838d75cacf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_args = dict(\n",
    "    current_section_chat=\"Interviewer: Could you confirm whether you used one hot encoding to encode the vategorical variables?\\nApplicant: No, I didn't use that.\",\n",
    "    is_completion_correct=1)\n",
    "completion_args = dict(route=\"0\")\n",
    "observation_prompt = model_metadata['prompt_template'].format(**prompt_args)\n",
    "completion = model_metadata['completion_template'].format(**completion_args)\n",
    "observation_details = dict(model_name=\"route_answer_to_confirm_what_applicant_did\", \n",
    "                               model_version=model_version,\n",
    "                               prompt_template=model_metadata['prompt_template'], \n",
    "                               completion_template=model_metadata['completion_template'], \n",
    "                               prompt_args=prompt_args, \n",
    "                               completion_args=completion_args,\n",
    "                               prompt = observation_prompt,\n",
    "                               completion=completion)\n",
    "\n",
    "prepare_data.add_observation_to_finetuning_datasets(observation_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404a2b43-9b96-49f4-baec-e24a1b33cef9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ask_what_other_options_applicant_considered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1e852b-880f-4fe2-b7a2-ba95a3266e2a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## version 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "019f970d-31b4-4dba-948b-cb1dd11e1bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_version_metadata = {\n",
    "    'model_version': None,\n",
    "    'prompt_template': \\\n",
    "\"\"\"Current section chat:\n",
    "{current_section_chat}\n",
    "\n",
    "Details:\n",
    "Is question correct: {is_completion_correct}\n",
    "###\n",
    "\"\"\",\n",
    "    'completion_template': \\\n",
    "\"\"\"Interviewer: {interviewer_dialogue}\"\"\",\n",
    "    'kshot_header': \\\n",
    "\"\"\"Interviewer is interviewing Applicant for a job as a Data Scientist.\n",
    "Interviewer asks Applicant a question in the following format:\n",
    "\n",
    "Current section chat:\n",
    "$<Conversation so far between Interviewer and Applicant. This may be empty.>\n",
    "\n",
    "Details:\n",
    "Is question correct: $<1 or 0 - whether the question Interviewer asks is correct or not>\n",
    "###\n",
    "Interviewer: $<Interviewer's question about which other options the applicant considered for a particular topic>\n",
    "\n",
    "Below are some correct examples:\n",
    "\n",
    "\"\"\",\n",
    "    'finetuned_model_name': None\n",
    "}\n",
    "\n",
    "add_new_model_version(\"ask_what_other_options_applicant_considered\", new_model_version_metadata, set_as_best_model_version=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5857c01-bc3d-4b81-adfe-2d1f9557f0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metadata, model_version = get_model_metadata(\"ask_what_other_options_applicant_considered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16cac78d-4290-4f31-a8f3-b5edcbcd0d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_args = dict(\n",
    "    current_section_chat=\"Interviewer: From your submission, I see that you used a Random Forest model. Is that correct?\\nApplicant: No.\\nInterviewer: What algorithm did you use, then?\\nApplicant: I played around with Random Forest, but I ended up using SVM.\",\n",
    "    is_completion_correct=1)\n",
    "completion_args = dict(interviewer_dialogue=\"Besides Random Forest and SVM, did you consider any other options?\")\n",
    "observation_prompt = model_metadata['prompt_template'].format(**prompt_args)\n",
    "completion = model_metadata['completion_template'].format(**completion_args)\n",
    "observation_details = dict(model_name=\"ask_what_other_options_applicant_considered\", \n",
    "                               model_version=model_version,\n",
    "                               prompt_template=model_metadata['prompt_template'], \n",
    "                               completion_template=model_metadata['completion_template'], \n",
    "                               prompt_args=prompt_args, \n",
    "                               completion_args=completion_args,\n",
    "                               prompt = observation_prompt,\n",
    "                               completion=completion)\n",
    "\n",
    "prepare_data.add_observation_to_finetuning_datasets(observation_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed2cc15-12f8-4623-971a-577bb524fa5c",
   "metadata": {},
   "source": [
    "## version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d66fefd2-e5af-4115-832e-f0156ac09827",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_version_metadata = {\n",
    "    'model_version': None,\n",
    "    'prompt_template': \\\n",
    "\"\"\"Current section chat:\n",
    "{current_section_chat}\n",
    "\n",
    "Details:\n",
    "Is question correct: {is_completion_correct}\n",
    "###\n",
    "\"\"\",\n",
    "    'completion_template': \\\n",
    "\"\"\"Interviewer: {interviewer_dialogue}\n",
    "$$$\"\"\",\n",
    "    'kshot_header': \\\n",
    "\"\"\"Interviewer is interviewing Applicant for a job as a Data Scientist.\n",
    "Interviewer asks Applicant a question in the following format:\n",
    "\n",
    "Current section chat:\n",
    "$<Conversation so far between Interviewer and Applicant. This may be empty.>\n",
    "\n",
    "Details:\n",
    "Is question correct: $<1 or 0 - whether the question Interviewer asks is correct or not>\n",
    "###\n",
    "Interviewer: $<Interviewer's question about which other options the applicant considered for a particular topic>\n",
    "$$$\n",
    "\n",
    "Below are some correct examples:\n",
    "\n",
    "\"\"\",\n",
    "    'finetuned_model_name': None\n",
    "}\n",
    "\n",
    "add_new_model_version(\"ask_what_other_options_applicant_considered\", new_model_version_metadata, set_as_best_model_version=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5686f7a8-45ff-4be9-b4ed-2bfef878166c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# route_answer_to_ask_what_applicant_did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e212b9af-7f5b-4459-aaba-a57ebf34fbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_version_metadata = {\n",
    "    'model_version': None,\n",
    "    'prompt_template': \\\n",
    "\"\"\"Current section chat:\n",
    "{current_section_chat}\n",
    "\n",
    "Details:\n",
    "Is routing correct: {is_completion_correct}\n",
    "###\n",
    "\"\"\",\n",
    "    'completion_template': \\\n",
    "\"\"\"Route: {route}\"\"\",\n",
    "    'kshot_header': \\\n",
    "\"\"\"Interviewer is interviewing Applicant for a job as a Data Scientist.\n",
    "Interviewer assigns Applicant's answer to integer categories in the following format:\n",
    "\n",
    "Current section chat:\n",
    "$<Conversation so far between Interviewer and Applicant. This may be empty.>\n",
    "\n",
    "Details:\n",
    "Is routing correct: $<1 or 0 - whether the category Interviewer assigns to Applicant's answer is of the right type or not>\n",
    "###\n",
    "Route: $<whether applicant used an approach for a particular task (1) or did nothing (0)>\n",
    "\n",
    "Below are some correct examples:\n",
    "\n",
    "\"\"\",\n",
    "    'finetuned_model_name': None\n",
    "}\n",
    "\n",
    "add_new_model_version(\"route_answer_to_ask_what_applicant_did\", new_model_version_metadata, set_as_best_model_version=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b5feff5-1099-459f-a072-3a4f9f69077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metadata, model_version = get_model_metadata(\"route_answer_to_ask_what_applicant_did\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "419196b4-6d29-4887-9f12-38918e46b65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_args = dict(\n",
    "    current_section_chat=\"Interviewer: What algorithm did you use for training on the data?\\nApplicant: I used Lasso.\",\n",
    "    is_completion_correct=1)\n",
    "completion_args = dict(route=\"1\")\n",
    "observation_prompt = model_metadata['prompt_template'].format(**prompt_args)\n",
    "completion = model_metadata['completion_template'].format(**completion_args)\n",
    "observation_details = dict(model_name=\"route_answer_to_ask_what_applicant_did\", \n",
    "                               model_version=model_version,\n",
    "                               prompt_template=model_metadata['prompt_template'], \n",
    "                               completion_template=model_metadata['completion_template'], \n",
    "                               prompt_args=prompt_args, \n",
    "                               completion_args=completion_args,\n",
    "                               prompt = observation_prompt,\n",
    "                               completion=completion)\n",
    "\n",
    "prepare_data.add_observation_to_finetuning_datasets(observation_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59461f15-af9a-4324-9909-950f7b6c7287",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_args = dict(\n",
    "    current_section_chat=\"Interviewer: How did you tune the hyperparameters in your model?\\nApplicant: I didn't tune my hypers.\",\n",
    "    is_completion_correct=1)\n",
    "completion_args = dict(route=\"0\")\n",
    "observation_prompt = model_metadata['prompt_template'].format(**prompt_args)\n",
    "completion = model_metadata['completion_template'].format(**completion_args)\n",
    "observation_details = dict(model_name=\"route_answer_to_ask_what_applicant_did\", \n",
    "                               model_version=model_version,\n",
    "                               prompt_template=model_metadata['prompt_template'], \n",
    "                               completion_template=model_metadata['completion_template'], \n",
    "                               prompt_args=prompt_args, \n",
    "                               completion_args=completion_args,\n",
    "                               prompt = observation_prompt,\n",
    "                               completion=completion)\n",
    "\n",
    "prepare_data.add_observation_to_finetuning_datasets(observation_details)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
