{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4337541f-2004-4b28-b0c5-d3f5d4a1cf5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import openai\n",
    "import pandas as pd\n",
    "import logging\n",
    "from IPython.display import clear_output\n",
    "from copy import deepcopy\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from parse import parse\n",
    "\n",
    "from nodes import node_functions\n",
    "from finetuning import prepare_data\n",
    "from utils.graph import create_interview_flowchart\n",
    "from utils.utils import path_to_finetuning_data_folder, prepare_kshot_prompt_using_levenshtein_distance\n",
    "from nodes.node_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84eceaf2-fbe6-49d7-a4b9-db088533681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.models_metadata import get_model_metadata, create_models_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff686837-dca3-4f88-b7a7-060f548a9526",
   "metadata": {},
   "source": [
    "# -1: playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32b3a892-c0ac-4b0b-b75d-bb6726c20dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame({'raw_finetuning_dataset_index': [0,1,2], 'prompt': ['a', 'b', 'c'], 'completion': [1,2,3]}, \n",
    "                   index=[0, 1,2])\n",
    "b = pd.DataFrame({'completion': [10]}, \n",
    "                   index=[9])\n",
    "a = pd.concat((a, b), ignore_index=False)\n",
    "a.to_csv('a.csv', na_rep='NA', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "060273d3-cfe1-471f-9169-55a336e01c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('a.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "046fb19d-4013-4701-bb77-57ba46b6d823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   completion\n",
       "0           1\n",
       "1           2\n",
       "2           3\n",
       "9          10"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7549b9-2bef-499b-8371-c6cbc9debd6a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 0: setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0ee19ff5-d66a-48b8-bb8b-197cc207345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_models_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5713fc79-d2d9-45de-83b7-26affa1e6c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare_data.prepare_formatted_finetuning_dataset(model_name = \"ask_how_it_works\", model_version = \"4.1.23\")\n",
    "\n",
    "# prepare_data.prepare_formatted_finetuning_dataset(model_name = \"validate_answer_how_it_works\", model_version = \"4.1.23\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea49b33a-23c7-41c3-bf8b-9988cc0c253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "interview_flowchart, interview_flowchart_visual = create_interview_flowchart()\n",
    "# interview_flowchart_visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "094d9acf-5a38-41a5-b1a8-bda5217402e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat\n",
    "\n",
    "# each list within this variable is the conversation in a particular section. each string within that list is the ordered dialogue from each member of the interview\n",
    "chat_history_by_section = [[]]\n",
    "chat_history_by_line = []\n",
    "flattened_chat_history = \"\"\n",
    "\n",
    "# list of strings.\n",
    "# each string is the summary of that section\n",
    "chat_section_summaries = []\n",
    "\n",
    "# list of tuples containing the model called, the prompt, and the completion\n",
    "prompt_and_completions_so_far = []\n",
    "\n",
    "# list of the nodes that have been visited till the current point\n",
    "nodes_visited_names = []\n",
    "previous_node_section_name = None\n",
    "current_node_name = \"introduction-share_boilerplate\"\n",
    "current_node_section_name = \"introduction\"\n",
    "\n",
    "is_interview_complete = False\n",
    "\n",
    "carryover_data = dict(algorithm_selection=dict(subject='autoencoder'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92f334db-13bf-4cc5-8d90-ec016d8ab5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_node_name = \"algorithm_selection-ask_how_it_works\"\n",
    "\n",
    "# current_node = interview_flowchart.nodes[current_node_name]\n",
    "    \n",
    "# current_node_function_args = deepcopy(current_node['function_args'])\n",
    "# current_node_function_args['carryover_data'] = carryover_data\n",
    "# current_node_function_args['chat_history_by_section'] = chat_history_by_section\n",
    "\n",
    "# current_node_output = current_node['function'](**current_node_function_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325e71ae-125e-4b51-8c60-b5ab3de714e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "502fd34f-2397-4e6f-8928-0f75404bd9e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interviewer: Thank you for taking the time out to interview with us. \n",
      "    In this interview, we will cover a range of topics and ask questions to assess your skill level as a Data Scientist. \n",
      "    If you don't understand a question, feel free to ask questions to get clarification.\n",
      "    Let's get started.\n",
      "Interviewer: Can you explain to me how an autoencoder works?\n",
      "Applicant: It is a neural network that predicts the input, except the hidden layers in the model have a smaller size than the input layer. This forces the model to learn the most important patterns in the data. if the model is fed with an observation that is wildly different from the ones it generally sees, it will be unable to reconstruct the observation in the prediction. Because of this property, it is used for anomaly detection use cases.\n",
      "Interviewer: Okay, those were all the topics we wanted to cover. Thank you again for taking the time out to interview with us.\n",
      "    We will get back to you with our decision. Have a nice day!\n"
     ]
    }
   ],
   "source": [
    "while not is_interview_complete:   \n",
    "    # run function associated with current node. if it involves an LLM completion, get a label and add to finetuning dataset\n",
    "    current_node = interview_flowchart.nodes[current_node_name]\n",
    "    \n",
    "    current_node_function_args = deepcopy(current_node['function_args'])\n",
    "    current_node_function_args['carryover_data'] = carryover_data\n",
    "    current_node_function_args['chat_history_by_section'] = chat_history_by_section\n",
    "    \n",
    "    current_node_output = current_node['function'](**current_node_function_args)\n",
    "    \n",
    "    if current_node_output['new_chat_line']:\n",
    "        # store return values in appropriate variables (chat_history)\n",
    "        chat_history_by_section[-1].append(current_node_output['new_chat_line'])\n",
    "        chat_history_by_line.append(current_node_output['new_chat_line'])\n",
    "        flattened_chat_history += \"\\n\" + current_node_output['new_chat_line']\n",
    "        clear_output()\n",
    "        print(flattened_chat_history)\n",
    "    \n",
    "    # update nodes_visited\n",
    "    nodes_visited_names.append(current_node_name)\n",
    "    \n",
    "    # based on output value, identify next node to visit. update current_node\n",
    "    outgoing_edges = list(interview_flowchart.out_edges(current_node_name, data=True))\n",
    "    if len(outgoing_edges) == 0:\n",
    "        is_interview_complete = True\n",
    "    else:\n",
    "        edge_to_traverse = None\n",
    "        if len(outgoing_edges) == 1:\n",
    "            edge_to_traverse = outgoing_edges[0]\n",
    "        else:\n",
    "            for edge in outgoing_edges:\n",
    "                if current_node_output['routing_value'] in edge[-1]['passthrough_values']:\n",
    "                    edge_to_traverse = edge\n",
    "        previous_node_section_name = current_node_section_name\n",
    "        current_node_name = edge_to_traverse[1]\n",
    "        current_node_section_name = current_node_name.split(\"-\")[0]\n",
    "                    \n",
    "        # if we are in a new section (subgraph)\n",
    "        if current_node_section_name != previous_node_section_name:\n",
    "            # create a new list in chat_history_by_section\n",
    "            chat_history_by_section.append([])\n",
    "            # TODO: summarize the previous topic and add it to chat_topic_summaries\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82430895-5f0b-414e-ab14-ac530487f5f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['introduction-share_boilerplate', 'algorithm_selection-ask_how_it_works']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_visited_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "923852f7-5ebe-41ff-bd41-dad29dfca194",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data.validate_observations_for_finetuning_from_queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc9d5207-0252-4e4a-a4d9-9ac2a04789e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{amol}\" \\\n",
    "    .format(amol=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
