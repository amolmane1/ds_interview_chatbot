{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import prepare_chat_history, prepare_kshot_prompt_using_levenshtein_distance, default_arguments_for_openai_validation, create_openai_completion\n",
    "from utils.models_metadata import get_model_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_using_vtt(chat_history, question=\"NA\", provided_answer=\"NA\", model_name=\"validate_answer_to_custom_question\", model_version=None, ):\n",
    "    \"\"\"\n",
    "    Hits OpenAI's completion endpoint to validate the answer an applicant gives to a question. Returns the validation according to the completion template.\n",
    "\n",
    "        Parameters:\n",
    "                chat_history (list of strings): Conversation so far between the interviewer and applicant (first to most recent). Each string should start with either \"Interviewer: \" or \"Applicant: \".\n",
    "                question (string): Optional - The question whose answer we want to validate. If this is not passed, we validate the answer to the last question the interviewer asks in `chat_history`.\n",
    "                provided_answer (string): Optional - The expected answer for `question`. If this is not passed, we hope our model is able to figure out the right answer and validate the applicant's answer accordingly.\n",
    "                model_name (string): Optional - Which model from `models_metadata.json` we want to use to get a completion.\n",
    "                model_version (string): Optional - The version of `model_name` we want to use. If this is empty, `get_model_metadata` figures out the best model version from `models_metadata.json` and uses it.\n",
    "        Returns:\n",
    "                completion (string): A completion from OpenAI that validates the applicant's answer according to the completion template in `models_metadata.json` for the given `model_name` and `model_version`.\n",
    "    \"\"\"\n",
    "    prompt_args = dict(\n",
    "                    current_section_chat = prepare_chat_history(chat_history, max_length=800, empty_value='NA'),\n",
    "                    question = question,\n",
    "                    provided_answer = provided_answer,\n",
    "                    is_completion_correct = 1)\n",
    "    model_metadata, model_version = get_model_metadata(model_name, model_version)\n",
    "    observation_prompt = model_metadata['prompt_template'].format(**prompt_args)\n",
    "\n",
    "    kshot_prompt = prepare_kshot_prompt_using_levenshtein_distance(model_name=model_name, \n",
    "                                                                model_metadata=model_metadata, \n",
    "                                                                prompt_args=prompt_args, \n",
    "                                                                observation_prompt=observation_prompt)\n",
    "    completion = create_openai_completion(kshot_prompt, model_metadata=model_metadata, args=default_arguments_for_openai_validation)\n",
    "    return completion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation of response: 1\n",
      "Is question subjective: 1\n",
      "\n",
      "Subpoints made / expected: \n",
      "Subpoint: <KNN is faster than logistic regression when making inferences.><c><NA>\n",
      "Subpoint: <KNN is more prone to overfitting than logistic regression.><m><NA>\n",
      "\n",
      "Number of correct, missing, incorrect, irrelevant subpoints: 1, 1, 0, 0\n"
     ]
    }
   ],
   "source": [
    "completion = get_completion_using_vtt(\n",
    "    [\"Interviewer: What are the pros and cons of a knn classifier versus a logistic regression model?\",\n",
    "     \"Applicant: KNN is faster than logistic regression when making inferences.\"]\n",
    "     )\n",
    "print(completion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_interview_chatbot_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "41f12de9af4222e4b257cc56cd09168715a90beb6fcd186c29ab659bfe87472a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
